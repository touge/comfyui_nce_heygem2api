# cache_audio.py

import os
import tempfile
import torchaudio
import torch
import imageio
import numpy as np


def audio_to_tensor(
    cache_dir: str,
    audio_tensor: torch.Tensor,
    sample_rate: int,
    filename_prefix: str = "cached_audio_",
    audio_format: str = ".wav"
) -> str:
    """
    å°†ä¸€ä¸ªéŸ³é¢‘ Tensor ç¼“å­˜åˆ°ç£ç›˜ï¼Œå¹¶è¿”å›ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ã€‚

    å‚æ•°:
      cache_dir       â€“ ä¸´æ—¶æ–‡ä»¶å­˜æ”¾ç›®å½•ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºã€‚
      audio_tensor    â€“ åº”ä¸º [channels, samples] çš„ torch.Tensorã€‚
      sample_rate     â€“ éŸ³é¢‘é‡‡æ ·ç‡ (Hz)ã€‚
      filename_prefix â€“ ä¸´æ—¶æ–‡ä»¶å‰ç¼€ (é»˜è®¤ "cached_audio_")ã€‚
      audio_format    â€“ æ–‡ä»¶åç¼€/æ ¼å¼ (é»˜è®¤ ".wav")ã€‚

    è¿”å›:
      å†™å…¥ç£ç›˜åçš„ä¸´æ—¶æ–‡ä»¶ç»å¯¹è·¯å¾„ã€‚

    å¼‚å¸¸:
      åœ¨æ— æ³•å†™å…¥æ–‡ä»¶æˆ–ä¿å­˜éŸ³é¢‘æ—¶ï¼Œä¼šæŠ›å‡º RuntimeErrorã€‚
    """
    os.makedirs(cache_dir, exist_ok=True)

    try:
        with tempfile.NamedTemporaryFile(
            prefix=filename_prefix,
            suffix=audio_format,
            dir=cache_dir,
            delete=False
        ) as tmp_file:
            temp_filepath = tmp_file.name

        if audio_tensor.device.type != "cpu":
            audio_tensor = audio_tensor.cpu()

        # ğŸ›  ä¿®å¤ç‚¹ï¼šé™ç»´åˆ° [channels, samples]
        if audio_tensor.ndim == 3:
            # å‡è®¾ä¸º [1, C, S] å½¢å¼ï¼ˆå¸¸è§äº ComfyUIï¼‰
            audio_tensor = audio_tensor.squeeze(0)

        if audio_tensor.ndim != 2:
            raise ValueError(f"audio_tensor ç»´åº¦åº”ä¸º [channels, samples]ï¼Œä½†å½“å‰ä¸º {audio_tensor.shape}")

        torchaudio.save(temp_filepath, audio_tensor, sample_rate)

        return temp_filepath

    except (OSError, RuntimeError, ValueError) as e:
        raise RuntimeError(f"Error caching audio tensor: {e}") from e

def video_to_tensor(video_path: str) -> torch.Tensor:
    """
    è¯»å–æœ¬åœ°è§†é¢‘æ–‡ä»¶å¹¶è½¬ä¸º torch.Tensor æ ¼å¼ï¼ŒRGBï¼Œfloat32ï¼Œ[0, 1]ã€‚

    å‚æ•°:
      video_path â€“ æœ¬åœ° mp4 æ–‡ä»¶è·¯å¾„ã€‚

    è¿”å›:
      Tensor: [frames, height, width, channels]ï¼Œdtype=torch.float32

    å¼‚å¸¸:
      - FileNotFoundErrorï¼šæ–‡ä»¶ä¸å­˜åœ¨
      - RuntimeErrorï¼šè¯»å–å¤±è´¥æˆ–æ ¼å¼å¼‚å¸¸
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"[video_to_tensor] æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶: {video_path}")

    reader = imageio.get_reader(video_path)
    try:
        meta = reader.get_meta_data()
        height, width = meta["size"]
        expected_channels = 3

        expected_shape = (height, width, expected_channels)

        def frame_generator(reader, expected_shape):
            for i, frame in enumerate(reader):
                if frame.ndim == 2:
                    print(f"[video_to_tensor] ç¬¬ {i} å¸§ä¸ºç°åº¦å›¾åƒ shape={frame.shape}ï¼Œè·³è¿‡ã€‚")
                    continue
                if frame.shape[-1] == 1:
                    print(f"[video_to_tensor] ç¬¬ {i} å¸§é€šé“ä¸º 1ï¼Œè·³è¿‡: shape={frame.shape}")
                    continue
                if frame.shape[-1] == 4:
                    frame = frame[:, :, :3]  # å»é™¤ alpha é€šé“
                if frame.shape != expected_shape:
                    print(f"[video_to_tensor] ç¬¬ {i} å¸§å°ºå¯¸å¼‚å¸¸ï¼Œè·³è¿‡: shape={frame.shape}, é¢„æœŸ: {expected_shape}")
                    continue
                yield (frame.astype(np.float32) / 255.0)

        frames = list(frame_generator(reader, expected_shape))
        if len(frames) == 0:
            raise RuntimeError(f"[video_to_tensor] æ— æ³•ä» '{video_path}' ä¸­è¯»å–ä»»ä½•æœ‰æ•ˆå¸§")

        try:
            frames_np = np.stack(frames, axis=0).copy()
        except Exception as stack_err:
            raise RuntimeError(f"[video_to_tensor] np.stack å‡ºé”™: {stack_err}") from stack_err

        try:
            tensor = torch.from_numpy(frames_np).to(torch.float32)
        except Exception as tensor_err:
            raise RuntimeError(f"[video_to_tensor] è½¬æ¢ä¸º tensor å¤±è´¥: {tensor_err}") from tensor_err

        return tensor

    finally:
        reader.close()
